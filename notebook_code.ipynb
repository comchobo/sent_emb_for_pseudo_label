{"cells":[{"cell_type":"markdown","metadata":{"id":"xMhQl4w4B58p"},"source":["Set debug for mini_local mode. I'll use yaml for easy configuration, which requires 'directory args' only.\n","\n","debug -> internal mode (disable below modes)\n","\n","mini_local -> mini_test in local if True\n","\n","mini_lambda -> search hyperparameter if True\n","\n","main_lambda -> try main_test if True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F467dy6cB58p"},"outputs":[],"source":["from IPython import get_ipython"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7OWNDL66B58q"},"outputs":[],"source":["debug =  True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-8tSXcmXB58q"},"outputs":[],"source":["import yaml\n","import argparse\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument('--yaml_path', default='configs/baseline.yaml', type=str)\n","parser.add_argument('--mode', default='mini_local', type=str)\n","args = parser.parse_args(args=[])\n","\n","config = yaml.load(open(args.yaml_path, 'r'), Loader = yaml.Loader)\n","config = config[args.mode]\n","yaml_name = args.yaml_path[8:-5]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IrzQNUdhB58r"},"outputs":[],"source":["import os\n","try:\n","    os.mkdir(f'models')\n","    os.mkdir(f'res')\n","    os.mkdir(f'cache')\n","    os.mkdir(f'supervised_model')\n","except FileExistsError:\n","    pass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fzz2PaxcB58r"},"outputs":[],"source":["import torch\n","\n","if torch.cuda.is_available():\n","        device = torch.device('cuda')\n","else:\n","        device = torch.device('mps')"]},{"cell_type":"markdown","metadata":{"id":"dIr_500NB58r"},"source":["Set most parts of the hyperparameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QSN2StcZB58s"},"outputs":[],"source":["which_model = \\\n","{'mine':{\n","    'sent_emb_model_path':'sorryhyun/sentence-embedding-klue-large',\n","    'use_cls':False,\n","    'hidden_size':1024,\n","    }\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tthJCqGyB58s"},"outputs":[],"source":["save_cache=False\n","model_set_dict = which_model['mine']\n","num_proc = 4 if debug is False else 0"]},{"cell_type":"markdown","metadata":{"id":"3AHVffRTB58s"},"source":["Download pre-split files via *(deprecated hyperlink)*\n","\n","Auths for sharing are limited to a-ha empolyees"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bbB_plc3B58s","outputId":"f101feac-e685-416c-cbf7-38a103a39546"},"outputs":[],"source":["from datasets import load_from_disk\n","\n","if config['shard_num']>1:\n","    train_question_dataset = load_from_disk('data/train_question_dataset').shard(config['shard_num'], 0)\n","    train_answer_dataset = load_from_disk('data/train_answer_dataset').shard(config['shard_num'], 0)\n","    test_question_dataset = load_from_disk('data/test_question_dataset').shard(int(config['shard_num']/2), 0)\n","    test_answer_dataset = load_from_disk('data/test_answer_dataset').shard(int(config['shard_num']/2), 0)\n","else:\n","    train_question_dataset = load_from_disk('data/train_question_dataset')\n","    train_answer_dataset = load_from_disk('data/train_answer_dataset')\n","    test_question_dataset = load_from_disk('data/test_question_dataset')\n","    test_answer_dataset = load_from_disk('data/test_answer_dataset')\n","\n","train_question_dataset = train_question_dataset.train_test_split(test_size=0.1)\n","train_answer_dataset = train_answer_dataset.train_test_split(test_size=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y3gev3zVB58t"},"outputs":[],"source":["from datasets import Dataset\n","\n","def extract_contents(q_dataset, a_dataset):\n","    question_contents_extracted = {}\n","    answer_contents_extracted = {}\n","\n","    question_extracted = [(x['a'], x['b'], x['c'], x['d']) for x in q_dataset] # embargo\n","\n","    a,b,c,d = zip(*question_extracted)\n","    question_contents_extracted = {\n","        'paragraph': list(paragraph)\n","    }\n","    answer_extracted = [(x['a'], x['b'], x['c']) for x in a_dataset] # embargo\n","    a, b, c = zip(*answer_extracted)\n","    answer_contents_extracted = {\n","        'paragraph': list(paragraph)\n","    }\n","\n","    return Dataset.from_dict(question_contents_extracted), Dataset.from_dict(answer_contents_extracted)\n","\n","q_contents, a_contents = extract_contents(train_question_dataset['train'], train_answer_dataset['train'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dAZQUldhB58t","outputId":"329a46ba-f0af-4338-f590-3c61813ca449"},"outputs":[],"source":["from funcs.preprocessors import Preprocessor\n","preprocessor = Preprocessor(debug=debug, config=config)\n","\n","q_preprocessed= preprocessor.preprocess(q_contents)\n","a_preprocessed = preprocessor.preprocess(a_contents)"]},{"cell_type":"markdown","metadata":{"id":"gcYUmUrWB58t"},"source":["A method make_reps() will concat representations of question and question title automatically."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6GPYs6t-B58t"},"outputs":[],"source":["from funcs.embedders import Embedder\n","from funcs.tokenized_loader import Tokenized_loader\n","from torch.utils.data import DataLoader\n","import numpy as np\n","\n","def make_reps(preprocessed_data, is_question=True):\n","    tokenized_loader = Tokenized_loader(sent_emb_model_path=model_set_dict['sent_emb_model_path'], config=config)\n","\n","    all_outputs, contents_len, tokenized_data, indices, split_contents_flatten   =\\\n","        tokenized_loader.set_for_rep(preprocessed_data, is_question = is_question)\n","\n","    dataloader = DataLoader(tokenized_data, batch_size=config['batch_size'], num_workers=num_proc, pin_memory=True)\n","\n","    embedder = Embedder(sent_emb_model_path=model_set_dict['sent_emb_model_path'], device=device, config=config)\n","    all_outputs_res = embedder.run_rep_mean_pool(all_outputs, dataloader)\n","\n","    all_outputs_res = all_outputs_res.detach().cpu().numpy()\n","\n","    del embedder\n","    return all_outputs_res, indices, split_contents_flatten\n","\n","q_reps, q_indices, q_flatten = make_reps(q_preprocessed, is_question=True)\n","a_reps, a_indices, a_flatten = make_reps(a_preprocessed, is_question=False)\n","\n","flatten_texts = q_flatten + a_flatten\n","reps = np.concatenate((q_reps, a_reps))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7rDbah3-B58t"},"outputs":[],"source":["# import h5py, json\n","# if save_cache:\n","#     with h5py.File(f'cache/3q_reps', 'w') as hdf5_file:\n","#         dset = hdf5_file.create_dataset('q', data=q_reps, chunks=True, compression=\"gzip\", compression_opts=9)\n","#     with open(f'cache/3q_indices.json','w') as f: json.dump(q_indices,f)\n","\n","#     with h5py.File(f'cache/3a_reps', 'w') as hdf5_file:\n","#         dset = hdf5_file.create_dataset('a', data=a_reps, chunks=True, compression=\"gzip\", compression_opts=9)\n","#     with open(f'cache/3a_indices.json','w') as f: json.dump(a_indices,f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1xnQ3bpwB58u","outputId":"64fa96b1-edcc-4433-cf7b-aac8e69d85fe"},"outputs":[],"source":["import numpy as np\n","from utils.customized_com_det import community_detection\n","\n","def sample_and_cluster(reps, flatten_texts, threshold=0.6):\n","\n","    cluster_idx_dict = {} # cluster_label : index_of_reps\n","    cluster_text_dict = {} # cluster_label : sentence\n","\n","    if debug:\n","        sample_size = 2000\n","        sampled_indices = np.random.choice(len(reps), size=sample_size, replace=False)\n","        sampled_reps= reps[sampled_indices]\n","        sampled_texts = [flatten_texts[x] for x in sampled_indices]\n","\n","    elif 'main' in config['mode']:\n","        sample_size = len(flatten_texts)\n","        sampled_reps = reps\n","        sampled_texts = flatten_texts\n","\n","    else:\n","        sampled_reps = reps\n","        sampled_texts = flatten_texts\n","        sampled_indices = np.random.choice(len(reps), size=config['sample_size'], replace=False)\n","        sampled_reps= reps[sampled_indices]\n","        sampled_texts = [flatten_texts[x] for x in sampled_indices]\n","\n","    clusters  = community_detection(sampled_reps,  \\\n","        batch_size=config['batch_size'], min_community_size=config['comm_size'], threshold=threshold, show_progress_bar=True)\n","\n","    cluster_criteria = [torch.from_numpy(reps[x[0],:]) for x in clusters]\n","    cluster_criteria = torch.stack(cluster_criteria)\n","\n","    # out of clustered data would be regarded as 'ooc'\n","    # this will be the last label in supervised model\n","    ooc = len(clusters)\n","    flatten_cluster = [ooc for _ in range(config['sample_size'])]\n","\n","    for idx in range(len(clusters)):\n","        cluster_idx_dict[idx] = clusters[idx]\n","        cluster_text_dict[idx] = [sampled_texts[x] for x in clusters[idx]]\n","        for clustered_idx in clusters[idx]:\n","            flatten_cluster[clustered_idx] = idx\n","\n","    return cluster_criteria, cluster_idx_dict, cluster_text_dict, flatten_cluster\n","\n","cluster_criteria, cluster_idx_dict, cluster_text_dict, flatten_cluster =\\\n","    sample_and_cluster(reps, flatten_texts, threshold=config['cosine_threshold'])\n","\n","clustered_data = []\n","cluster_label = []\n","for key in cluster_text_dict.keys():\n","    clustered_data.append(cluster_text_dict[key])\n","    cluster_label.append([key for _ in range(len(cluster_text_dict[key]))])"]},{"cell_type":"markdown","metadata":{"id":"npB6yt74B58u"},"source":["Sample & test average performance. This is for mini-test-lambda."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j79aeYmLB58u","outputId":"7619644a-b694-4f4f-97a0-700346ac08d9"},"outputs":[],"source":["from transformers import set_seed\n","from utils.utils import get_flatten\n","import pickle, json\n","import os\n","\n","try:\n","    os.mkdir(f'models/{yaml_name}')\n","    os.mkdir(f'res/{yaml_name}')\n","    os.mkdir(f'cache/{yaml_name}')\n","except FileExistsError:\n","    pass\n","\n","for n, seed_num in enumerate(config['seed_list']):\n","    set_seed(seed_num)\n","    cluster_criteria, cluster_idx_dict, cluster_text_dict, flatten_cluster =\\\n","        sample_and_cluster(reps, flatten_texts, threshold=config['cosine_threshold'])\n","\n","    clustered_data = []\n","    cluster_label = []\n","    for key in cluster_text_dict.keys():\n","        clustered_data.append(cluster_text_dict[key])\n","        cluster_label.append([key for _ in range(len(cluster_text_dict[key]))])\n","\n","    train_text, _ = get_flatten(clustered_data)\n","    train_label, _ = get_flatten(cluster_label)\n","    train_dataset = Dataset.from_dict({'text':train_text, 'label':train_label})\n","    train_dataset.save_to_disk(f'cache/{yaml_name}/train_dataset_{str(n)}')\n","\n","    torch.save(cluster_criteria, f'models/{yaml_name}/cluster_criteria_{str(n)}')\n","    with open(f'res/{yaml_name}/cluster_dict_{str(n)}.pickle', 'wb') as f:\n","        pickle.dump(cluster_idx_dict, f, pickle.HIGHEST_PROTOCOL)\n","    with open(f'res/{yaml_name}/cluster_text_dict_{str(n)}.json', 'w') as f:\n","        json.dump(cluster_text_dict, f, ensure_ascii=False, indent=4)\n","\n","    torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"25RXfANqB58u"},"source":["Do same procedure on split set, dev and test."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CjwpwB5KB58u","outputId":"1453e1a5-cd37-4b58-ee52-bada2f3637e6"},"outputs":[],"source":["dev_q_contents, dev_a_contents = extract_contents(\n","    train_question_dataset['test'], train_answer_dataset['test'])\n","\n","dev_q_preprocessed= preprocessor.preprocess(dev_q_contents)\n","dev_a_preprocessed= preprocessor.preprocess(dev_a_contents)\n","\n","q_reps, q_indices, q_flatten = make_reps(dev_q_preprocessed, is_question=True)\n","a_reps, a_indices, a_flatten = make_reps(dev_a_preprocessed, is_question=False)\n","\n","dev_flatten_texts = q_flatten + a_flatten\n","dev_reps = np.concatenate((q_reps, a_reps))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iCDGPonpB58u","outputId":"d2d4bcf5-20dd-497a-d0e8-8e7e2db82f74"},"outputs":[],"source":["test_q_contents, test_a_contents = extract_contents(test_question_dataset, test_answer_dataset)\n","\n","test_q_preprocessed= preprocessor.preprocess(test_q_contents)\n","test_a_preprocessed= preprocessor.preprocess(test_a_contents)\n","\n","q_reps, q_indices, q_flatten = make_reps(test_q_preprocessed, is_question=True)\n","a_reps, a_indices, a_flatten = make_reps(test_a_preprocessed, is_question=False)\n","\n","test_flatten_texts = q_flatten + a_flatten\n","test_reps = np.concatenate((q_reps, a_reps))"]},{"cell_type":"markdown","metadata":{"id":"0VIt74OlB58v"},"source":["Predict their cluster, like pseudo-labeling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mgK_2uq0B58v"},"outputs":[],"source":["def predict_cluster(rep_tensor, cluster_criteria, threshold=0.6):\n","    rep_tensor = torch.from_numpy(rep_tensor)\n","    eps = 1e-8\n","    rep_norm = torch.nn.functional.normalize(rep_tensor, p=2, dim=1).to(device)\n","    criteria_norm = torch.nn.functional.normalize(cluster_criteria, p=2, dim=1).to(device)\n","    cos_sim_matrix = torch.mm(rep_norm, criteria_norm.t())\n","    sim_mt = cos_sim_matrix.clamp(min=eps)\n","    res = sim_mt.argmax(dim=1)\n","    ooc = len(cluster_criteria)\n","    return [res[x].item() if sim_mt[x,res[x]]>=threshold else ooc\n","            for x in range(rep_tensor.shape[0])]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KtPz02sPB58v"},"outputs":[],"source":["for n in range(len(config['seed_list'])):\n","    cluster_criteria_path = f'models/{yaml_name}/cluster_criteria_{n}'\n","    cluster_criteria = torch.load(cluster_criteria_path,  map_location=device)\n","\n","    dev_labels = predict_cluster(dev_reps, cluster_criteria, threshold=config['cosine_threshold'])\n","    dev_dataset = Dataset.from_dict({'text':dev_flatten_texts, 'label':dev_labels})\n","\n","    test_labels = predict_cluster(test_reps, cluster_criteria, threshold=config['cosine_threshold'])\n","    test_dataset = Dataset.from_dict({'text':test_flatten_texts, 'label':test_labels})"]},{"cell_type":"markdown","metadata":{"id":"88ckT6T0B58v"},"source":["Evaluate via distillation using psuedo-Supervised-model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7jTCmQE8B58v","outputId":"90a67e3a-969d-4e0e-aa08-8fd4c285690f"},"outputs":[],"source":["from funcs.trainer import BERT_Trainer\n","import json\n","\n","BERT_model_name = 'monologg/koelectra-base-v3-discriminator'\n","predicted_res = []\n","achieved_scores= []\n","\n","for seed in config['seed_list']:\n","    set_seed(seed)\n","    if 'main' in args.mode:\n","        output_path = f'supervised_model_main/{yaml_name}_seed_{str(seed)}'\n","    else:\n","        output_path = f'supervised_model/{yaml_name}_seed_{str(seed)}'\n","\n","    try:\n","        os.mkdir(output_path)\n","    except FileExistsError:\n","        pass\n","\n","    bert_trainer = BERT_Trainer(\n","        pretrained_model_path =BERT_model_name, output_path=output_path,\n","        debug=debug, num_labels = len(cluster_criteria), config=config)\n","\n","    bert_trainer.train_with_optimization(train_dataset = train_dataset, dev_dataset = dev_dataset, mode=config['mode'], batch_size = config['batch_size'])\n","    predicted_labels = bert_trainer.test(test_dataset = test_dataset)\n","    predicted_res.append(list(predicted_labels.label_ids))\n","    achieved_scores.append(predicted_labels.metrics['test_f1'])\n","\n","    del bert_trainer\n","    torch.cuda.empty_cache()\n","\n","total_res = {'mean_score':np.mean(achieved_scores), 'score_std':np.std(achieved_scores)}\n","if 'main' in args.mode:\n","    with open(f'res_main/{yaml_name}_results.json','w') as f: json.dump(total_res, f, indent=4)\n","    with open(f'res_main/{yaml_name}_results_labels.pickle','wb') as f: pickle.dump(predicted_res, f)\n","else:\n","    with open(f'res/{yaml_name}_results.json','w') as f: json.dump(total_res, f, indent=4)\n","    with open(f'res/{yaml_name}_results_labels.pickle','wb') as f: pickle.dump(predicted_res, f)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
